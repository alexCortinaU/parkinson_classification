{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys; sys.path.insert(0, os.path.abspath(\"../\"))\n",
    "from pathlib import Path\n",
    "this_path = Path().resolve()\n",
    "import numpy as np\n",
    "import torch\n",
    "import SimpleITK as sitk\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import pytorch_lightning as pl\n",
    "import torchio as tio\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "\n",
    "from dataset.hmri_dataset import HMRIControlsDataModule, HMRIPDDataModule\n",
    "from models.pl_model import Model_AE\n",
    "from utils.utils import save_nifti_from_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct(data, model, save_img=False, out_dir=None, type='pd'):\n",
    "    patches, locations, sampler, subject, subj_id = data\n",
    "    input_imgs = patches.to(model.device)\n",
    "    aggregator = tio.data.GridAggregator(sampler)  \n",
    "    with torch.no_grad():\n",
    "        x_hat = model(input_imgs)\n",
    "    aggregator.add_batch(x_hat, locations)\n",
    "    reconstructed = aggregator.get_output_tensor()\n",
    "\n",
    "    # Compute reconstruction error\n",
    "    subject = subject['image'][tio.DATA]\n",
    "    diff = [torch.pow(subject[i] - reconstructed[i], 2) for i in range(subject.shape[0])]\n",
    "    rerror = torch.sqrt(torch.sum(torch.stack(diff), dim=0))\n",
    "    rerror = rerror.cpu().numpy()\n",
    "    \n",
    "    if out_dir is None:\n",
    "        out_dir = Path('/home/alejandrocu/Documents/parkinson_classification/reconstructions') / Path(ckpt_path).parent.parent.parent.name\n",
    "        out_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "    if save_img:\n",
    "        save_nifti_from_array(subj_id=subj_id,\n",
    "                              arr=reconstructed[0].cpu().numpy(),\n",
    "                              path=out_dir / f'{type}_{subj_id}_recon.nii.gz')\n",
    "        save_nifti_from_array(subj_id=subj_id,\n",
    "                              arr=rerror,\n",
    "                              path=out_dir / f'{type}_{subj_id}_re_error.nii.gz')\n",
    "        save_nifti_from_array(subj_id=subj_id,\n",
    "                              arr=subject[0].cpu().numpy(),\n",
    "                              path=out_dir / f'{type}_{subj_id}_original.nii.gz')\n",
    "    \n",
    "    return rerror"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hc_idx = 1\n",
    "pd_idx = 1\n",
    "ckpt_path = Path('/home/alejandrocu/Documents/parkinson_classification/p2_hmri_outs/aehmri-da00_bz32_mse_adam_lr0.001-v4/version_0/checkpoints/epoch=187-val_loss=0.0054-val_mse=0.0054.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alejandrocu/Documents/parkinson_classification/dataset/hmri_dataset.py:428: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.md_df.drop(self.md_df[self.md_df.id == drop_id].index, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drop subjects ['sub-058', 'sub-016', 'sub-025']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model_AE(\n",
       "  (criterion): MSELoss()\n",
       "  (train_acc): BinaryAccuracy()\n",
       "  (val_acc): BinaryAccuracy()\n",
       "  (train_auroc): BinaryAUROC()\n",
       "  (val_auroc): BinaryAUROC()\n",
       "  (train_f1): BinaryF1Score()\n",
       "  (val_f1): BinaryF1Score()\n",
       "  (train_mse): MeanSquaredError()\n",
       "  (val_mse): MeanSquaredError()\n",
       "  (net): AutoEncoder(\n",
       "    (encode): Sequential(\n",
       "      (encode_0): Convolution(\n",
       "        (conv): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "        (adn): ADN(\n",
       "          (N): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (A): PReLU(num_parameters=1)\n",
       "        )\n",
       "      )\n",
       "      (encode_1): Convolution(\n",
       "        (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "        (adn): ADN(\n",
       "          (N): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (A): PReLU(num_parameters=1)\n",
       "        )\n",
       "      )\n",
       "      (encode_2): Convolution(\n",
       "        (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "        (adn): ADN(\n",
       "          (N): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (A): PReLU(num_parameters=1)\n",
       "        )\n",
       "      )\n",
       "      (encode_3): Convolution(\n",
       "        (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "        (adn): ADN(\n",
       "          (N): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (A): PReLU(num_parameters=1)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (intermediate): Identity()\n",
       "    (decode): Sequential(\n",
       "      (decode_0): Sequential(\n",
       "        (conv): Convolution(\n",
       "          (conv): ConvTranspose3d(256, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1), bias=False)\n",
       "          (adn): ADN(\n",
       "            (N): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (A): PReLU(num_parameters=1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (decode_1): Sequential(\n",
       "        (conv): Convolution(\n",
       "          (conv): ConvTranspose3d(128, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1), bias=False)\n",
       "          (adn): ADN(\n",
       "            (N): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (A): PReLU(num_parameters=1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (decode_2): Sequential(\n",
       "        (conv): Convolution(\n",
       "          (conv): ConvTranspose3d(64, 32, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1), bias=False)\n",
       "          (adn): ADN(\n",
       "            (N): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (A): PReLU(num_parameters=1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (decode_3): Sequential(\n",
       "        (conv): Convolution(\n",
       "          (conv): ConvTranspose3d(32, 1, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1), bias=False)\n",
       "          (adn): ADN(\n",
       "            (A): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read config file\n",
    "exp_dir = ckpt_path.parent.parent.parent\n",
    "with open(exp_dir /'config_dump.yml', 'r') as f:\n",
    "    cfg = list(yaml.load_all(f, yaml.SafeLoader))[0]\n",
    "\n",
    "# create dataset\n",
    "root_dir = Path('/mnt/scratch/7TPD/mpm_run_acu/bids/derivatives/hMRI')\n",
    "md_df = pd.read_csv(this_path.parent/'bids_3t.csv')\n",
    "md_df_hc = md_df[md_df['group'] == 0]\n",
    "md_df_pd = md_df[md_df['group'] == 1]\n",
    "data = HMRIControlsDataModule(md_df=md_df_hc,\n",
    "                                root_dir=root_dir, \n",
    "                                **cfg['dataset'])\n",
    "data.prepare_data()\n",
    "data.setup()\n",
    "hc_patches, hc_locations, hc_sampler, hc_subject = data.get_grid(subj=hc_idx)\n",
    "hc_subj_id = data.md_df_train.iloc[hc_idx]['id']\n",
    "\n",
    "hc_data = [hc_patches, hc_locations, hc_sampler, hc_subject, hc_subj_id]\n",
    "\n",
    "data_pd = HMRIPDDataModule(md_df=md_df_pd,\n",
    "                            root_dir=root_dir,  \n",
    "                            **cfg['dataset'])\n",
    "data_pd.prepare_data()\n",
    "data_pd.setup()\n",
    "pd_patches, pd_locations, pd_sampler, pd_subject = data_pd.get_grid(subj=pd_idx)\n",
    "\n",
    "pd_subj_id = data_pd.md_df.iloc[pd_idx]['id']\n",
    "\n",
    "pd_data = [pd_patches, pd_locations, pd_sampler, pd_subject, pd_subj_id]\n",
    "# create model\n",
    "model = Model_AE.load_from_checkpoint(ckpt_path, net='autoencoder', **cfg['model'])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aehmri-da00_bz32_l1_adam_lr0.001-v4'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = 'l1'\n",
    "cfg['exp_name'] = f\"aehmri-da00_bz32_{loss}_adam_lr0.001-v4\"\n",
    "cfg['exp_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = reconstruct(pd_data, model, save_img=True)\n",
    "_ = reconstruct(hc_data, model, save_img=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "7tpd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "abb5c6cfe726d303d00479e363228a1d7c1be6d2a698fc4501daea35327bdcc9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
