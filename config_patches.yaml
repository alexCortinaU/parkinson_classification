pl_trainer:
  max_epochs: 200
  devices:
  - 0
  accelerator: gpu
  precision: 16
  log_every_n_steps: 5

training:
  early_stopping:  False
  monitor_ckpt: val_loss # val_acc, val_f1, val_auroc
  display_recons: True

dataset:
  train_num_workers: 4
  train_batch_size: 32
  val_num_workers: 4
  val_batch_size: 32
  reshape_size: 180
  patch_size: 64
  map_type: 
    - MTsat
    # - R1
  queue_length: 128
  samples_per_volume: 9
  random_state: 42
  windowed_dataset: True
  brain_masked: True
  shuffle: True

# should match arguments in the module class
model:
  in_channels: 1
  loss: l1 # l1, mse
  optimizer_class: adam # sgd, adam, rmsprop
  learning_rate: 0.001
  sch_patience: -1
  momentum: 0 # 0.9  
  weight_decay: 0 # 0.0001    

exp_name: aehmri-da00_bz32_l1_adam_lr0.001-v4
